{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Machine Unlearning\n",
        "\n",
        "Can you unlearn something?\n",
        "\n",
        "Your task here is the following: given a network pre-trained on some data, you want to finetune it to selectively forget a class, and learn a new class.\n",
        "\n",
        "As an initial approach, you may do the following.\n",
        "\n",
        "Start with a MNIST classifier pre-trained on a subset of the\n",
        "digits.\n",
        "\n",
        "Now replace one of the learned digits, say the class “6”, with a new digit, say “3”.\n",
        "\n",
        "A possible way to proceed is to identify which weights are more involved in the prediction of class “6”, freeze all the rest, and train with a loss that favors the “3” while penalizing the “6”.\n",
        "\n",
        "Test this baseline and see whether it brings you anywhere. Are there any pitfalls in this idea? Does it work? Use it as a first line of attack to understand the problem.\n",
        "\n",
        "Starting from these baseline tests, devise a new unlearning procedure.\n",
        "\n",
        "You can improve upon this baseline, make up your own idea from scratch, or check the literature to get ideas.\n",
        "\n",
        "If you use an existing approach, you must add something new, for example by testing it on some new data modality (e.g., audio), by studying more extreme cases, failures, weaknesses, or by making it more efficient, and so on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "mnist_classifier(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "    (1): LeakyReLU(negative_slope=0.01)\n",
              "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "    (6): LeakyReLU(negative_slope=0.01)\n",
              "    (7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
              "    (8): ReLU()\n",
              "    (9): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(3, 3), bias=False)\n",
              "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (12): LeakyReLU(negative_slope=0.01)\n",
              "    (13): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
              "    (14): Conv2d(128, 256, kernel_size=(5, 5), stride=(1, 1), padding=(3, 3), bias=False)\n",
              "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (16): LeakyReLU(negative_slope=0.01)\n",
              "    (17): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
              "  )\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "    (5): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): LeakyReLU(negative_slope=0.01)\n",
              "    (7): Linear(in_features=4096, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# test model\n",
        "import source.mnist_net as mnist_net\n",
        "import torch\n",
        "\n",
        "simple_model = mnist_net.mnist_classifier()\n",
        "simple_model.load_state_dict(torch.load(\"data/models/MNIST/simple/weights.pth\", weights_only=True))\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "simple_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'test' from 'source.mnist_net' (/home/stefano/Documents/GitHub/Machine_Unlearning/source/mnist_net.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# test simple_model on MNIST\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmnist_net\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train, test\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'test' from 'source.mnist_net' (/home/stefano/Documents/GitHub/Machine_Unlearning/source/mnist_net.py)"
          ]
        }
      ],
      "source": [
        "# test simple_model on MNIST\n",
        "from source.mnist_net import train, test\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.Grayscale(),\n",
        "        transforms.ToTensor(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "mnist_test = torchvision.datasets.MNIST(\n",
        "    root=\"data/db\",\n",
        "    train=False,\n",
        "    transform=transform,\n",
        "    download=True,\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    mnist_test,\n",
        "    batch_size=1024,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        ")\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "mnist_net.test(simple_model, test_loader, loss_fn, device, True)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
